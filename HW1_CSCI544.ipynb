{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9JRnHqVdenP",
        "outputId": "4cea6877-005b-49d3-e341-4d49c1e6987f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "p5l86yxvdenQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /Users/hrishikesh/miniconda3/envs/myenv/lib/python3.10/site-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/hrishikesh/miniconda3/envs/myenv/lib/python3.10/site-packages (from bs4) (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/hrishikesh/miniconda3/envs/myenv/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install bs4 # in case you don't have it installed\n",
        "\n",
        "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBC96GEddenR"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eheZHyzTdenS",
        "outputId": "67ed84fe-2474-4ef4-9499-3b93babd2c2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/jc/l_cy7_tj5pn7bp93mtmcrhg80000gn/T/ipykernel_89570/1494580249.py:1: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataframe = pd.read_csv(\"https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\", sep=\"\\t\", on_bad_lines=\"skip\")\n"
          ]
        }
      ],
      "source": [
        "dataframe = pd.read_csv(\"https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\", sep=\"\\t\", on_bad_lines=\"skip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwpuqJ_PdenT"
      },
      "source": [
        "## Keep Reviews and Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jExD9OUFdenT",
        "outputId": "f6562afe-0f93-4915-d492-70ae733854d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Three sample reviews before data cleaning + preprocessing.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Great product.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>What's to say about this commodity item except...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  star_rating                                        review_body\n",
              "0           5                                     Great product.\n",
              "1           5  What's to say about this commodity item except...\n",
              "2           5    Haven't used yet, but I am sure I will like it."
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = dataframe[[\"star_rating\", \"review_body\"]]\n",
        "print( \"- Three sample reviews before data cleaning + preprocessing.\\n\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of reviews having rating 5.0 : 1582704\n",
            "Number of reviews having rating 4.0 : 418348\n",
            "Number of reviews having rating 1.0 : 306967\n",
            "Number of reviews having rating 3.0 : 193680\n",
            "Number of reviews having rating 2.0 : 138381\n"
          ]
        }
      ],
      "source": [
        "df.loc[:, 'star_rating'] = pd.to_numeric(df.star_rating, errors=\"coerce\")\n",
        "df = df.dropna()\n",
        "rating_stats = df.star_rating.value_counts()\n",
        "for i , j in rating_stats.items():\n",
        "    print(f'Number of reviews having rating {i} : {j}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UDJReLMdenU"
      },
      "source": [
        " ## We form three classes and select 100000 reviews randomly from each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "gzg-ycThdenU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "- Statistics of three classes :\n",
            "\n",
            "Positive review: 2001052, Neutral review: 193680, Negative review: 445348\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I ordered them from Discount Office Supplies a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Really nice metallic colors. I use them to sig...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Just so you know it prints okay at best photos...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  star_rating                                        review_body  class\n",
              "0         5.0  I ordered them from Discount Office Supplies a...      1\n",
              "1         5.0  Really nice metallic colors. I use them to sig...      1\n",
              "2         4.0  Just so you know it prints okay at best photos...      1"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print( \"\\n\\n- Statistics of three classes :\\n\")\n",
        "distribution = df.star_rating.value_counts()\n",
        "print (f'Positive review: {distribution[4]+distribution[5]}, Neutral review: {distribution[3]}, Negative review: {distribution[1]+distribution[2]}')\n",
        "\n",
        "# droping rows with neutral reviews i.e 3\n",
        "df.drop(df[df.star_rating == 3].index, inplace=True)\n",
        "df[\"class\"] = df.star_rating.apply( lambda x : 1 if x > 3 else 0)\n",
        "df1 = df[df[\"class\"] == 1].sample(100000)\n",
        "df2 = df[df[\"class\"] == 0].sample(100000)\n",
        "\n",
        "dataset = pd.concat([df1,df2],ignore_index=True)\n",
        "dataset.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xwzS9hVdenU"
      },
      "source": [
        "# Data Cleaning\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCetHd4PdenU"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHDG_y4JdenV",
        "outputId": "e7efe134-d39e-4d3f-ee2a-02bef062080b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average reiviews length before cleaning data : 317.917045, Average reiviews length after cleaning data : 302.11495\n"
          ]
        }
      ],
      "source": [
        "# Average review length\n",
        "print(\"Average reiviews length before cleaning data :\",dataset.review_body.apply(len).mean(),end=\",\")\n",
        "\n",
        "\n",
        "# - convert the all reviews into the lower case.\n",
        "dataset.review_body = dataset.review_body.str.lower()\n",
        "\n",
        "# - remove the HTML and URLs from the reviews\n",
        "dataset.review_body = dataset.review_body.str.replace(r'<[^<>]*>', '', regex=True)\n",
        "dataset.review_body = dataset.review_body.apply(lambda x : re.sub('http[s]?://\\S+','', x))\n",
        "\n",
        "# - remove non-alphabetical characters\n",
        "dataset.review_body = dataset.review_body.apply(lambda x : re.sub('[^a-z\\s\\']', '', x))\n",
        "\n",
        "# - remove extra spaces\n",
        "dataset.review_body = dataset.review_body.str.strip()\n",
        "\n",
        "# - remove multiple spaces in between review body\n",
        "dataset.review_body = dataset.review_body.str.replace(r'^\\s*|\\s\\s*', ' ', regex=True)\n",
        "\n",
        "# - perform contractions on the reviews=\n",
        "contraction_dict = {\n",
        "    \"i'm\": \"i am\",\n",
        "    \"you're\": \"you are\",\n",
        "    \"he's\": \"he is\",\n",
        "    \"she's\": \"she is\",\n",
        "    \"they're\": \"they are\",\n",
        "    \"we're\": \"we are\",\n",
        "    \"it's\": \"it is\",\n",
        "    \"that's\": \"that is\",\n",
        "    \"here's\": \"here is\",\n",
        "    \"there's\": \"there is\",\n",
        "    \"who's\": \"who is\",\n",
        "    \"where's\": \"where is\",\n",
        "    \"when's\": \"when is\",\n",
        "    \"why's\": \"why is\",\n",
        "    \"what's\": \"what is\",\n",
        "    \"how's\": \"how is\",\n",
        "    \"everybody's\": \"everybody is\",\n",
        "    \"nobody's\": \"nobody is\",\n",
        "    \"something's\": \"something is\",\n",
        "    \"so's\": \"so is\",\n",
        "    \"i'll\": \"i will\",\n",
        "    \"you'll\": \"you will\",\n",
        "    \"he'll\": \"he will\",\n",
        "    \"she'll\": \"she will\",\n",
        "    \"they'll\": \"they will\",\n",
        "    \"it'll\": \"it will\",\n",
        "    \"we'll\": \"we will\",\n",
        "    \"that'll\": \"that will\",\n",
        "    \"this'll\": \"this will\",\n",
        "    \"these'll\": \"these will\",\n",
        "    \"there'll\": \"there will\",\n",
        "    \"where'll\": \"where will\",\n",
        "    \"who'll\": \"who will\",\n",
        "    \"what'll\": \"what will\",\n",
        "    \"how'll\": \"how will\",\n",
        "    \"i've\": \"i have\",\n",
        "    \"you've\": \"you have\",\n",
        "    \"he's\": \"he has\",\n",
        "    \"she's\": \"she has\",\n",
        "    \"we've\": \"we have\",\n",
        "    \"they've\": \"they have\",\n",
        "    \"should've\": \"should have\",\n",
        "    \"could've\": \"could have\",\n",
        "    \"would've\": \"would have\",\n",
        "    \"might've\": \"might have\",\n",
        "    \"must've\": \"must have\",\n",
        "    \"what've\": \"what have\",\n",
        "    \"what's\": \"what has\",\n",
        "    \"where've\": \"where have\",\n",
        "    \"where's\": \"where has\",\n",
        "    \"there've\": \"there have\",\n",
        "    \"there's\": \"there has\",\n",
        "    \"these've\": \"these have\",\n",
        "    \"who's\": \"who has\",\n",
        "    \"don't\": \"do not\",\n",
        "    \"can't\": \"cannot\",\n",
        "    \"mustn't\": \"must not\",\n",
        "    \"aren't\": \"are not\",\n",
        "    \"couldn't\": \"could not\",\n",
        "    \"wouldn't\": \"would not\",\n",
        "    \"shouldn't\": \"should not\",\n",
        "    \"isn't\": \"is not\",\n",
        "    \"doesn't\": \"does not\",\n",
        "    \"didn't\": \"did not\",\n",
        "    \"hasn't\": \"has not\",\n",
        "    \"hadn't\": \"had not\",\n",
        "    \"haven't\": \"have not\",\n",
        "    \"wasn't\": \"was not\",\n",
        "    \"won't\": \"will not\",\n",
        "    \"weren't\": \"were not\",\n",
        "    \"ain't\": \"am not\",\n",
        "    \"let's\": \"let us\",\n",
        "    \"y'all\": \"you all\",\n",
        "    \"where'd\": \"where did\",\n",
        "    \"how'd\": \"how did\",\n",
        "    \"why'd\": \"why did\",\n",
        "    \"who'd\": \"who did\",\n",
        "    \"when'd\": \"when did\",\n",
        "    \"what'd\": \"what did\",\n",
        "    \"g'day\": \"good day\",\n",
        "    \"ma'am\": \"madam\",\n",
        "    \"o'clock\": \"of the clock\"\n",
        "}\n",
        "\n",
        "dataset.review_body = dataset.review_body.apply( lambda x : \" \".join([contraction_dict[word] if word in contraction_dict else word for word in x.split()]) )\n",
        "\n",
        "# Average review length\n",
        "print(\" Average reiviews length after cleaning data :\",dataset.review_body.apply(len).mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Alw_pAsdenV"
      },
      "source": [
        "## remove the stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "m7OG0SRrdenV",
        "outputId": "2a336e5b-d535-4f7d-b829-86e642919112"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/hrishikesh/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Average review length\n",
        "review_length_before_preprocessing = dataset.review_body.apply(len).mean()\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')\n",
        "dataset[\"review_body_lammatized\"] = dataset.review_body.apply( lambda x : ' '.join([i for i in x.split() if i not in (stop_words)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A1boh_LdenW"
      },
      "source": [
        "## perform lemmatization  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "bG22Kr0CdenW",
        "outputId": "a4c61cdb-b5bd-4f87-e8f7-59c64736f8d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/hrishikesh/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/hrishikesh/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/hrishikesh/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Three sample reviews after data cleaning + preprocessing.\n",
            "Average reiviews length before Pre-processing data : 302.11495,Average reiviews length after Pre-processing data : 181.883135\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import defaultdict\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_word_according_pos ( statement ):\n",
        "\n",
        "  tag_map = defaultdict(lambda : wn.NOUN)\n",
        "  tag_map['J'] = wn.ADJ\n",
        "  tag_map['V'] = wn.VERB\n",
        "  tag_map['R'] = wn.ADV\n",
        "\n",
        "  tokens = word_tokenize(statement)\n",
        "  answer = []\n",
        "  for token, tag in pos_tag(tokens):\n",
        "      answer.append(lemmatizer.lemmatize(token, tag_map[tag[0]]))\n",
        "  return ' '.join(answer)\n",
        "\n",
        "dataset[\"review_body_lammatized\"] = dataset.review_body_lammatized.apply( lambda x : lemmatize_word_according_pos(x))\n",
        "print(\"Three sample reviews after data cleaning + preprocessing.\")\n",
        "print(\"Average reiviews length before Pre-processing data :\",review_length_before_preprocessing,end=\",\")\n",
        "print(\"Average reiviews length after Pre-processing data :\",dataset.review_body_lammatized.apply(len).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>class</th>\n",
              "      <th>review_body_lammatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>i ordered them from discount office supplies a...</td>\n",
              "      <td>1</td>\n",
              "      <td>ordered discount office supply receive day ord...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>really nice metallic colors i use them to sign...</td>\n",
              "      <td>1</td>\n",
              "      <td>really nice metallic color use sign canvas wra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>just so you know it prints okay at best photos...</td>\n",
              "      <td>1</td>\n",
              "      <td>know print okay best photo high contrast low d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  star_rating                                        review_body  class  \\\n",
              "0         5.0  i ordered them from discount office supplies a...      1   \n",
              "1         5.0  really nice metallic colors i use them to sign...      1   \n",
              "2         4.0  just so you know it prints okay at best photos...      1   \n",
              "\n",
              "                              review_body_lammatized  \n",
              "0  ordered discount office supply receive day ord...  \n",
              "1  really nice metallic color use sign canvas wra...  \n",
              "2  know print okay best photo high contrast low d...  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSrTou3ddenW"
      },
      "source": [
        "# TF-IDF Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "H_9yGmOWdenW",
        "outputId": "a467b541-abd8-42b2-ba7e-d566863d2804"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "review_list = dataset.review_body_lammatized.tolist()\n",
        "result = tfidf.fit_transform(review_list)\n",
        "features = tfidf.get_feature_names_out()\n",
        "tfidf_dataset = pd.DataFrame( data = result.toarray(), columns = features )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aaa</th>\n",
              "      <th>abandon</th>\n",
              "      <th>ability</th>\n",
              "      <th>able</th>\n",
              "      <th>absolute</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>absorb</th>\n",
              "      <th>absurd</th>\n",
              "      <th>abuse</th>\n",
              "      <th>...</th>\n",
              "      <th>youtube</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>zebra</th>\n",
              "      <th>zero</th>\n",
              "      <th>zip</th>\n",
              "      <th>zipper</th>\n",
              "      <th>zire</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.248742</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    aa  aaa  abandon  ability  able  absolute  absolutely  absorb  absurd  \\\n",
              "0  0.0  0.0      0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
              "1  0.0  0.0      0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
              "2  0.0  0.0      0.0      0.0   0.0       0.0         0.0     0.0     0.0   \n",
              "\n",
              "   abuse  ...  youtube   yr  yrs  zebra      zero  zip  zipper  zire  zone  \\\n",
              "0    0.0  ...      0.0  0.0  0.0    0.0  0.000000  0.0     0.0   0.0   0.0   \n",
              "1    0.0  ...      0.0  0.0  0.0    0.0  0.000000  0.0     0.0   0.0   0.0   \n",
              "2    0.0  ...      0.0  0.0  0.0    0.0  0.248742  0.0     0.0   0.0   0.0   \n",
              "\n",
              "   zoom  \n",
              "0   0.0  \n",
              "1   0.0  \n",
              "2   0.0  \n",
              "\n",
              "[3 rows x 5000 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_dataset.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train and Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(tfidf_dataset, dataset[\"class\"], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(160000, 5000) (160000,) (40000, 5000) (40000,)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KBD5lmjdenX"
      },
      "source": [
        "# Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "p5tLCtQ5denX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data Metrix (Perceptron):  Accuracy : 0.872125 , Precision : 0.8612543528640936 , Recall : 0.8871973702301049 , F1 Score : 0.8740333940796926\n",
            "Testing Data Metrix (Perceptron): Accuracy : 0.8575 , Precision : 0.845993706124425 , Recall : 0.845993706124425 , F1 Score : 0.8597716984845504\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron \n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "perceptron = Perceptron(eta0=0.1) \n",
        "perceptron.fit(x_train, y_train) \n",
        "train_pred = perceptron.predict(x_train)\n",
        "\n",
        "accuracy = accuracy_score(y_train, train_pred) \n",
        "precision = precision_score(y_train, train_pred) \n",
        "recall = recall_score(y_train, train_pred) \n",
        "f1 = f1_score(y_train, train_pred) \n",
        "\n",
        "print(\"Training data Metrix (Perceptron): \",\"Accuracy :\", accuracy , \", Precision :\", precision,\", Recall :\", recall,\", F1 Score :\", f1)\n",
        "\n",
        "y_pred = perceptron.predict(x_test)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_pred) \n",
        "precision_test = precision_score(y_test, y_pred) \n",
        "recall_test = recall_score(y_test, y_pred) \n",
        "f1_test = f1_score(y_test, y_pred) \n",
        "\n",
        "print(\"Testing Data Metrix (Perceptron):\",\"Accuracy :\", accuracy_test , \", Precision :\", precision_test,\", Recall :\", precision_test,\", F1 Score :\", f1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn-YA5t2denX"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data Metrix (SVM):  Accuracy : 0.89953125 , Precision : 0.9013509780779951 , Recall : 0.8972839876510805 , F1 Score : 0.8993128848189511\n",
            "Testing Data Metrix (SVM): Accuracy : 0.885875 , Precision : 0.8873267724442659 , Recall : 0.8873267724442659 , F1 Score : 0.8856147736099627\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "svm_model = svm.LinearSVC(dual=\"auto\") \n",
        "svm_model.fit(x_train, y_train) \n",
        "train_pred = svm_model.predict(x_train)\n",
        "\n",
        "accuracy = accuracy_score(y_train, train_pred) \n",
        "precision = precision_score(y_train, train_pred) \n",
        "recall = recall_score(y_train, train_pred) \n",
        "f1 = f1_score(y_train, train_pred) \n",
        "\n",
        "print(\"Training data Metrix (SVM): \",\"Accuracy :\", accuracy , \", Precision :\", precision,\", Recall :\", recall,\", F1 Score :\", f1)\n",
        "\n",
        "\n",
        "y_pred = svm_model.predict(x_test)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_pred) \n",
        "precision_test = precision_score(y_test, y_pred) \n",
        "recall_test = recall_score(y_test, y_pred) \n",
        "f1_test = f1_score(y_test, y_pred) \n",
        "\n",
        "print(\"Testing Data Metrix (SVM):\",\"Accuracy :\", accuracy_test , \", Precision :\", precision_test,\", Recall :\", precision_test,\", F1 Score :\", f1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrQyzCdWdenY"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "1KHeaMtCdenY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data Metrix (Logistic Regression):  Accuracy : 0.89613125 , Precision : 0.8995310609116579 , Recall : 0.8918969590160861 , F1 Score : 0.8956977437474503\n",
            "Testing Data Metrix (Logistic Regression): Accuracy : 0.887375 , Precision : 0.8904012905827788 , Recall : 0.8904012905827788 , F1 Score : 0.8868914609957568\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_reg = LogisticRegression(max_iter=5000) \n",
        "logistic_reg.fit(x_train, y_train) \n",
        "train_pred = logistic_reg.predict(x_train)\n",
        "\n",
        "accuracy = accuracy_score(y_train, train_pred) \n",
        "precision = precision_score(y_train, train_pred) \n",
        "recall = recall_score(y_train, train_pred) \n",
        "f1 = f1_score(y_train, train_pred) \n",
        "\n",
        "print(\"Training data Metrix (Logistic Regression): \",\"Accuracy :\", accuracy , \", Precision :\", precision,\", Recall :\", recall,\", F1 Score :\", f1)\n",
        "\n",
        "\n",
        "y_pred = logistic_reg.predict(x_test)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_pred) \n",
        "precision_test = precision_score(y_test, y_pred) \n",
        "recall_test = recall_score(y_test, y_pred) \n",
        "f1_test = f1_score(y_test, y_pred) \n",
        "\n",
        "print(\"Testing Data Metrix (Logistic Regression):\",\"Accuracy :\", accuracy_test , \", Precision :\", precision_test,\", Recall :\", precision_test,\", F1 Score :\", f1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erPToUBBdenY"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "6Z8diBFbdenZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data Metrix (Naive Bayes):  Accuracy : 0.85950625 , Precision : 0.8582513388965002 , Recall : 0.8612871373754797 , F1 Score : 0.8597665583261072\n",
            "Testing data Metrix (Naive Bayes):  Accuracy : 0.854625 , Precision : 0.8553027265437049 , Recall : 0.8553027265437049 , F1 Score : 0.854424834146952\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naiveBayes = MultinomialNB()\n",
        "naiveBayes.fit(x_train,y_train)\n",
        "\n",
        "train_pred = naiveBayes.predict(x_train)\n",
        "\n",
        "accuracy = accuracy_score(y_train, train_pred) \n",
        "precision = precision_score(y_train, train_pred) \n",
        "recall = recall_score(y_train, train_pred) \n",
        "f1 = f1_score(y_train, train_pred) \n",
        "\n",
        "print(\"Training data Metrix (Naive Bayes): \",\"Accuracy :\", accuracy , \", Precision :\", precision,\", Recall :\", recall,\", F1 Score :\", f1)\n",
        "\n",
        "y_pred = naiveBayes.predict(x_test)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_pred) \n",
        "precision_test = precision_score(y_test, y_pred) \n",
        "recall_test = recall_score(y_test, y_pred) \n",
        "f1_test = f1_score(y_test, y_pred) \n",
        "\n",
        "print(\"Testing data Metrix (Naive Bayes): \",\"Accuracy :\", accuracy_test , \", Precision :\", precision_test,\", Recall :\", precision_test,\", F1 Score :\", f1_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
